{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcee23bd",
   "metadata": {},
   "source": [
    "# Visual Wake Word Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a258f29",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries\n",
    "\n",
    "This cell imports essential libraries: Gradio for the interface, OpenCV for image processing, the Akida library for model execution, and NumPy and Plotly for data handling and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35785368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kmanninen/miniconda3/envs/akida_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-24 13:03:59.035998: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-24 13:03:59.510864: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-24 13:03:59.511154: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-24 13:03:59.593856: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-24 13:03:59.786653: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-24 13:04:02.035773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/kmanninen/miniconda3/envs/akida_env/lib/python3.11/site-packages/onnxscript/converter.py:816: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "\n",
    "from cnn2snn import set_akida_version, AkidaVersion\n",
    "import akida\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5d0b6",
   "metadata": {},
   "source": [
    "### Gauge Creation Function\n",
    "\n",
    "Defines a function using Plotly to create a gauge visualization for metrics such as frames per second during image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31006aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gauge(value):\n",
    "    fig = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=value,\n",
    "        gauge={'axis': {'range': [0, 30]}},\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "    ))\n",
    "    fig.update_layout(width=400, height=300)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944ee12",
   "metadata": {},
   "source": [
    "### Softmax Function for Arrays\n",
    "\n",
    "Implements a softmax function to convert model outputs into probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0507dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax for an array of values\n",
    "def softmaxArray(values):\n",
    "    # Assuming array shape is (1, 1, 1, x), flatten to get the values\n",
    "    values = values.ravel()\n",
    "    exp_values = np.exp(values)\n",
    "    sum_exp = np.sum(exp_values)\n",
    "    softmax_values = exp_values / sum_exp\n",
    "    return softmax_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e976a9",
   "metadata": {},
   "source": [
    "### Image Configuration and Output Decoding\n",
    "\n",
    "Sets up image parameters and label names, and includes a function to preprocess images and decode predictions into readable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48246e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 96\n",
    "image_y = 96\n",
    "image_z = 3\n",
    "labels = [\"no person\", \"person\"]\n",
    "def decodeOutput(inp):\n",
    "        global akida_model\n",
    "        inp = cv2.resize(inp, (image_x, image_y))\n",
    "        inp = inp.reshape((-1, image_x, image_y, image_z))\n",
    "        timer_start = time.time()\n",
    "        predictions = softmaxArray(akida_model.predict(inp))\n",
    "        frame_time = time.time() - timer_start\n",
    "        fps = 1 / frame_time if frame_time > 0 else 0\n",
    "        confidences = {labels[i]: predictions[i] for i in range(len(predictions))}\n",
    "\n",
    "        return confidences, fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8830e8d",
   "metadata": {},
   "source": [
    "### Image Classification Wrapper\n",
    "\n",
    "A function that processes an image, decodes it, and returns classification confidences with a gauge visualization of processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bccd78e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(inp):\n",
    "\n",
    "  confidences, fps = decodeOutput(inp)\n",
    "\n",
    "  return confidences, create_gauge(round(fps, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afcdd6",
   "metadata": {},
   "source": [
    "### Load Pre-trained Model\n",
    "\n",
    "Loads a pre-trained quantized model for visual wake word detection via `akida_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc99fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"akidanet_0.25_96_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " rescaling (QuantizedRescal  (None, 96, 96, 3)         0         \n",
      " ing)                                                            \n",
      "                                                                 \n",
      " conv_0 (QuantizedConv2D)    (None, 48, 48, 8)         224       \n",
      "                                                                 \n",
      " conv_0/relu (QuantizedReLU  (None, 48, 48, 8)         16        \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_1 (QuantizedConv2D)    (None, 48, 48, 16)        1168      \n",
      "                                                                 \n",
      " conv_1/relu (QuantizedReLU  (None, 48, 48, 16)        32        \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_2 (QuantizedConv2D)    (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " conv_2/relu (QuantizedReLU  (None, 24, 24, 32)        64        \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_3 (QuantizedConv2D)    (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " conv_3/relu (QuantizedReLU  (None, 24, 24, 32)        64        \n",
      " )                                                               \n",
      "                                                                 \n",
      " dw_separable_4 (QuantizedD  (None, 12, 12, 32)        352       \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_4 (QuantizedC  (None, 12, 12, 64)        2112      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_4/relu (Quant  (None, 12, 12, 64)        128       \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_5 (QuantizedD  (None, 12, 12, 64)        704       \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_5 (QuantizedC  (None, 12, 12, 64)        4160      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_5/relu (Quant  (None, 12, 12, 64)        128       \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_6 (QuantizedD  (None, 6, 6, 64)          704       \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_6 (QuantizedC  (None, 6, 6, 128)         8320      \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_6/relu (Quant  (None, 6, 6, 128)         256       \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_7 (QuantizedD  (None, 6, 6, 128)         1408      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_7 (QuantizedC  (None, 6, 6, 128)         16512     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_7/relu (Quant  (None, 6, 6, 128)         256       \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_8 (QuantizedD  (None, 6, 6, 128)         1408      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_8 (QuantizedC  (None, 6, 6, 128)         16512     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_8/relu (Quant  (None, 6, 6, 128)         256       \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_9 (QuantizedD  (None, 6, 6, 128)         1408      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_9 (QuantizedC  (None, 6, 6, 128)         16512     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_9/relu (Quant  (None, 6, 6, 128)         256       \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_10 (Quantized  (None, 6, 6, 128)         1408      \n",
      " DepthwiseConv2D)                                                \n",
      "                                                                 \n",
      " pw_separable_10 (Quantized  (None, 6, 6, 128)         16512     \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " pw_separable_10/relu (Quan  (None, 6, 6, 128)         256       \n",
      " tizedReLU)                                                      \n",
      "                                                                 \n",
      " dw_separable_11 (Quantized  (None, 6, 6, 128)         1408      \n",
      " DepthwiseConv2D)                                                \n",
      "                                                                 \n",
      " pw_separable_11 (Quantized  (None, 6, 6, 128)         16512     \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " pw_separable_11/relu (Quan  (None, 6, 6, 128)         256       \n",
      " tizedReLU)                                                      \n",
      "                                                                 \n",
      " dw_separable_12 (Quantized  (None, 3, 3, 128)         1408      \n",
      " DepthwiseConv2D)                                                \n",
      "                                                                 \n",
      " pw_separable_12 (Quantized  (None, 3, 3, 256)         33024     \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " pw_separable_12/relu (Quan  (None, 3, 3, 256)         512       \n",
      " tizedReLU)                                                      \n",
      "                                                                 \n",
      " dw_separable_13 (Quantized  (None, 3, 3, 256)         2816      \n",
      " DepthwiseConv2D)                                                \n",
      "                                                                 \n",
      " pw_separable_13 (Quantized  (None, 3, 3, 256)         65792     \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " pw_separable_13/relu (Quan  (None, 3, 3, 256)         0         \n",
      " tizedReLU)                                                      \n",
      "                                                                 \n",
      " pw_separable_13/global_avg  (None, 256)               2         \n",
      "  (QuantizedGlobalAveragePo                                      \n",
      " oling2D)                                                        \n",
      "                                                                 \n",
      " dropout (QuantizedDropout)  (None, 256)               0         \n",
      "                                                                 \n",
      " classifier (QuantizedDense  (None, 2)                 514       \n",
      " )                                                               \n",
      "                                                                 \n",
      " dequantizer (Dequantizer)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 227268 (887.77 KB)\n",
      "Trainable params: 222418 (868.82 KB)\n",
      "Non-trainable params: 4850 (18.95 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from quantizeml import load_model\n",
    "from akida_models import fetch_file\n",
    "\n",
    "# Load the pre-trained quantized model\n",
    "model_file = fetch_file(\n",
    "    fname=\"akidanet_vww_i8_w4_a4.h5\",\n",
    "    origin=\"https://data.brainchip.com/models/AkidaV2/akidanet/akidanet_vww_i8_w4_a4.h5\",\n",
    "    cache_subdir='models')\n",
    "model_keras_quantized = load_model(model_file)\n",
    "model_keras_quantized.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79851eff",
   "metadata": {},
   "source": [
    "### Model Conversion\n",
    "\n",
    "Converts the pre-trained Keras model to an Akida-compatible format and prints a summary of the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "618bfb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model Summary                 \n",
      "______________________________________________\n",
      "Input shape  Output shape  Sequences  Layers\n",
      "==============================================\n",
      "[96, 96, 3]  [1, 1, 2]     1          26    \n",
      "______________________________________________\n",
      "\n",
      "___________________________________________________________________\n",
      "Layer (type)                       Output shape  Kernel shape    \n",
      "\n",
      "================= SW/conv_0-dequantizer (Software) ================\n",
      "\n",
      "conv_0 (InputConv2D)               [48, 48, 8]   (3, 3, 3, 8)    \n",
      "___________________________________________________________________\n",
      "conv_1 (Conv2D)                    [48, 48, 16]  (3, 3, 8, 16)   \n",
      "___________________________________________________________________\n",
      "conv_2 (Conv2D)                    [24, 24, 32]  (3, 3, 16, 32)  \n",
      "___________________________________________________________________\n",
      "conv_3 (Conv2D)                    [24, 24, 32]  (3, 3, 32, 32)  \n",
      "___________________________________________________________________\n",
      "dw_separable_4 (DepthwiseConv2D)   [12, 12, 32]  (3, 3, 32, 1)   \n",
      "___________________________________________________________________\n",
      "pw_separable_4 (Conv2D)            [12, 12, 64]  (1, 1, 32, 64)  \n",
      "___________________________________________________________________\n",
      "dw_separable_5 (DepthwiseConv2D)   [12, 12, 64]  (3, 3, 64, 1)   \n",
      "___________________________________________________________________\n",
      "pw_separable_5 (Conv2D)            [12, 12, 64]  (1, 1, 64, 64)  \n",
      "___________________________________________________________________\n",
      "dw_separable_6 (DepthwiseConv2D)   [6, 6, 64]    (3, 3, 64, 1)   \n",
      "___________________________________________________________________\n",
      "pw_separable_6 (Conv2D)            [6, 6, 128]   (1, 1, 64, 128) \n",
      "___________________________________________________________________\n",
      "dw_separable_7 (DepthwiseConv2D)   [6, 6, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_7 (Conv2D)            [6, 6, 128]   (1, 1, 128, 128)\n",
      "___________________________________________________________________\n",
      "dw_separable_8 (DepthwiseConv2D)   [6, 6, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_8 (Conv2D)            [6, 6, 128]   (1, 1, 128, 128)\n",
      "___________________________________________________________________\n",
      "dw_separable_9 (DepthwiseConv2D)   [6, 6, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_9 (Conv2D)            [6, 6, 128]   (1, 1, 128, 128)\n",
      "___________________________________________________________________\n",
      "dw_separable_10 (DepthwiseConv2D)  [6, 6, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_10 (Conv2D)           [6, 6, 128]   (1, 1, 128, 128)\n",
      "___________________________________________________________________\n",
      "dw_separable_11 (DepthwiseConv2D)  [6, 6, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_11 (Conv2D)           [6, 6, 128]   (1, 1, 128, 128)\n",
      "___________________________________________________________________\n",
      "dw_separable_12 (DepthwiseConv2D)  [3, 3, 128]   (3, 3, 128, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_12 (Conv2D)           [3, 3, 256]   (1, 1, 128, 256)\n",
      "___________________________________________________________________\n",
      "dw_separable_13 (DepthwiseConv2D)  [3, 3, 256]   (3, 3, 256, 1)  \n",
      "___________________________________________________________________\n",
      "pw_separable_13 (Conv2D)           [1, 1, 256]   (1, 1, 256, 256)\n",
      "___________________________________________________________________\n",
      "classifier (Dense1D)               [1, 1, 2]     (256, 2)        \n",
      "___________________________________________________________________\n",
      "dequantizer (Dequantizer)          [1, 1, 2]     N/A             \n",
      "___________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from cnn2snn import convert\n",
    "\n",
    "# Convert the model\n",
    "akida_model = convert(model_keras_quantized)\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ea800d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Akida devices found, running on CPU.\n"
     ]
    }
   ],
   "source": [
    "with set_akida_version(AkidaVersion.v2):\n",
    "            devices = akida.devices()\n",
    "            if len(devices) > 0:\n",
    "                print(f'Available devices: {[dev.desc for dev in devices]}')\n",
    "                device = devices[0]\n",
    "                print(device.version)\n",
    "                try:\n",
    "                    akida_model.map(device)\n",
    "                    print(f\"Mapping to Akida device {device.desc}.\")\n",
    "                    mappedDevice = device.version\n",
    "                except Exception as e:\n",
    "                    print(\"Model not compatible with FPGA. Running on CPU.\")\n",
    "                    mappedDevice = \"CPU\"\n",
    "            else:\n",
    "                print(\"No Akida devices found, running on CPU.\")\n",
    "                mappedDevice = \"CPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ee5a7",
   "metadata": {},
   "source": [
    "### Gradio Interface Setup\n",
    "\n",
    "Creates a Gradio interface to capture webcam images, display device information, and stream classified images using the Akida model. The interface shows live predictions and frame processing speeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b0e8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theme = gr.themes.Base(\n",
    "    text_size=\"sm\",\n",
    "    spacing_size=\"sm\",\n",
    "    radius_size=\"sm\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(\n",
    "    title=\"Brainchip\",\n",
    "    fill_width=True,\n",
    "    fill_height=True,\n",
    "    delete_cache=[180, 600],\n",
    "    theme=theme\n",
    ") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "        <h1 style=\"text-align: center;\">Akida Cloud</h1>\n",
    "        <br>\n",
    "        \"\"\")\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"## Image Classification\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_img = gr.Image(sources=[\"webcam\"], type=\"numpy\")\n",
    "        with gr.Column():\n",
    "            gr.Markdown(f\"\"\"Device: {mappedDevice}\"\"\")\n",
    "            output_label = gr.Label(num_top_classes=3)\n",
    "            plot = gr.Plot(label=\"Frames per second\")\n",
    "        dep = input_img.stream(classify_image, [input_img], [output_label, plot],\n",
    "                                time_limit=30, stream_every=0.1, concurrency_limit=30)        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akida_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
