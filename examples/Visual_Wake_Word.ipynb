{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcee23bd",
   "metadata": {},
   "source": [
    "# Visual Wake Word Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a258f29",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries\n",
    "\n",
    "This cell imports essential libraries: Gradio for the interface, OpenCV for image processing, the Akida library for model execution, and NumPy and Plotly for data handling and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35785368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "\n",
    "from cnn2snn import set_akida_version, AkidaVersion\n",
    "import akida\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5d0b6",
   "metadata": {},
   "source": [
    "### Gauge Creation Function\n",
    "\n",
    "Defines a function using Plotly to create a gauge visualization for metrics such as frames per second during image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31006aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gauge(value):\n",
    "    fig = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=value,\n",
    "        gauge={'axis': {'range': [0, 30]}},\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "    ))\n",
    "    fig.update_layout(width=400, height=300)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944ee12",
   "metadata": {},
   "source": [
    "### Softmax Function for Arrays\n",
    "\n",
    "Implements a softmax function to convert model outputs into probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax for an array of values\n",
    "def softmaxArray(values):\n",
    "    # Assuming array shape is (1, 1, 1, x), flatten to get the values\n",
    "    values = values.ravel()\n",
    "    exp_values = np.exp(values)\n",
    "    sum_exp = np.sum(exp_values)\n",
    "    softmax_values = exp_values / sum_exp\n",
    "    return softmax_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e976a9",
   "metadata": {},
   "source": [
    "### Image Configuration and Output Decoding\n",
    "\n",
    "Sets up image parameters and label names, and includes a function to preprocess images and decode predictions into readable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48246e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 96\n",
    "image_y = 96\n",
    "image_z = 3\n",
    "labels = [\"no person\", \"person\"]\n",
    "def decodeOutput(inp):\n",
    "        global akida_model\n",
    "        inp = cv2.resize(inp, (image_x, image_y))\n",
    "        inp = inp.reshape((-1, image_x, image_y, image_z))\n",
    "        timer_start = time.time()\n",
    "        predictions = softmaxArray(akida_model.predict(inp))\n",
    "        frame_time = time.time() - timer_start\n",
    "        fps = 1 / frame_time if frame_time > 0 else 0\n",
    "        confidences = {labels[i]: predictions[i] for i in range(len(predictions))}\n",
    "\n",
    "        return confidences, fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8830e8d",
   "metadata": {},
   "source": [
    "### Image Classification Wrapper\n",
    "\n",
    "A function that processes an image, decodes it, and returns classification confidences with a gauge visualization of processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd78e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(inp):\n",
    "\n",
    "  confidences, fps = decodeOutput(inp)\n",
    "\n",
    "  return confidences, create_gauge(round(fps, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afcdd6",
   "metadata": {},
   "source": [
    "### Load Pre-trained Model\n",
    "\n",
    "Loads a pre-trained quantized model for visual wake word detection via `akida_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from akida_models.model_io import load_model\n",
    "akida_model = load_model(\"models/tenn_spatiotemporal_eye_buffer_i8_w8_a8.fbz\")\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0efcf",
   "metadata": {},
   "source": [
    "Map the `akida_model` onto the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with set_akida_version(AkidaVersion.v2):\n",
    "            devices = akida.devices()\n",
    "            if len(devices) > 0:\n",
    "                print(f'Available devices: {[dev.desc for dev in devices]}')\n",
    "                device = devices[0]\n",
    "                print(device.version)\n",
    "                try:\n",
    "                    akida_model.map(device)\n",
    "                    print(f\"Mapping to Akida device {device.desc}.\")\n",
    "                    mappedDevice = device.version\n",
    "                except Exception as e:\n",
    "                    print(\"Model not compatible with FPGA. Running on CPU.\")\n",
    "                    mappedDevice = \"CPU\"\n",
    "            else:\n",
    "                print(\"No Akida devices found, running on CPU.\")\n",
    "                mappedDevice = \"CPU\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ee5a7",
   "metadata": {},
   "source": [
    "### Gradio Interface Setup\n",
    "\n",
    "Creates a Gradio interface to capture webcam images, display device information, and stream classified images using the Akida model. The interface shows live predictions and frame processing speeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme = gr.themes.Base(\n",
    "    text_size=\"sm\",\n",
    "    spacing_size=\"sm\",\n",
    "    radius_size=\"sm\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(\n",
    "    title=\"Brainchip\",\n",
    "    fill_width=True,\n",
    "    fill_height=True,\n",
    "    delete_cache=[180, 600],\n",
    "    theme=theme\n",
    ") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "        <h1 style=\"text-align: center;\">Akida Cloud</h1>\n",
    "        <br>\n",
    "        \"\"\")\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"## Image Classification\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_img = gr.Image(sources=[\"webcam\"], type=\"numpy\")\n",
    "        with gr.Column():\n",
    "            gr.Markdown(f\"\"\"Device: {mappedDevice}\"\"\")\n",
    "            output_label = gr.Label(num_top_classes=3)\n",
    "            plot = gr.Plot(label=\"Frames per second\")\n",
    "        dep = input_img.stream(classify_image, [input_img], [output_label, plot],\n",
    "                                time_limit=30, stream_every=0.1, concurrency_limit=30)        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akida_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
