{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c43cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from cnn2snn import set_akida_version, AkidaVersion\n",
    "import akida\n",
    "from akida_models.tenn_spatiotemporal.eye_preprocessing import preprocess_data\n",
    "from akida_models.tenn_spatiotemporal.eye_losses import process_detector_prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_segment_npy(file_path, time_window_us=10_000, segment_duration_us=500_000):\n",
    "    \"\"\"\n",
    "    Loads event data from a structured .npy file, splits it into 500ms segments,\n",
    "    and converts each segment into model-compatible frames using preprocess_data.\n",
    "    Args:\n",
    "        file_path (str): Path to the .npy event file (with fields: 'p', 'x', 'y', 't').\n",
    "        preprocess_data_fn (callable): preprocess_data function to apply per segment.\n",
    "        time_window_us (int): Time window per frame (default: 10,000µs).\n",
    "        segment_duration_us (int): Duration of each segment in microseconds (default: 500,000µs).\n",
    "    Returns:\n",
    "        list of tf.Tensor: List of processed frame tensors.\n",
    "    \"\"\"\n",
    "    # Load structured event array\n",
    "    data = np.load(file_path)\n",
    "    # print(f\"Loaded {data.shape[0]} events\")\n",
    "\n",
    "    # Convert structured fields to float32 arrays\n",
    "    p = data['p'].astype('float32')\n",
    "    x = data['x'].astype('float32')\n",
    "    y = data['y'].astype('float32')\n",
    "    t = data['t'].astype('float32')\n",
    "\n",
    "    # Prepare stacked event tensor (4, N)\n",
    "    trial = tf.stack([p, x, y, t], axis=0)\n",
    "\n",
    "    # Time range\n",
    "    t_start = t[0]\n",
    "    t_end = t[-1]\n",
    "\n",
    "    frames_list = []\n",
    "    segment_list = []\n",
    "\n",
    "    current_time = t_start\n",
    "    while current_time + segment_duration_us <= t_end:\n",
    "        # Get indices for the current 500ms window\n",
    "        start_idx = np.searchsorted(t, current_time, side='left')\n",
    "        end_idx = np.searchsorted(t, current_time + segment_duration_us, side='right')\n",
    "\n",
    "        # Slice event segment\n",
    "        segment = tf.stack([\n",
    "            p[start_idx:end_idx],\n",
    "            x[start_idx:end_idx],\n",
    "            y[start_idx:end_idx],\n",
    "            t[start_idx:end_idx]\n",
    "        ], axis=0)\n",
    "\n",
    "        # Dummy label (e.g. center)\n",
    "        label = tf.convert_to_tensor([[0.5, 0.5, 0]], dtype=tf.float32)\n",
    "\n",
    "        # Preprocess segment into frames\n",
    "        frames, _ = preprocess_data(\n",
    "            events=segment,\n",
    "            label=label,\n",
    "            train_mode=False,\n",
    "            frames_per_segment=1,\n",
    "            spatial_downsample=(6, 6),\n",
    "            time_window=time_window_us\n",
    "        )\n",
    "\n",
    "        frames_list.append(frames)\n",
    "        segment_list.append(segment)\n",
    "        current_time += segment_duration_us\n",
    "\n",
    "    print(f\"Processed {len(frames_list)} segments of 500ms each.\")\n",
    "    return frames_list, segment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e6fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_all, segment_all = load_and_segment_npy(\"eye_tracking_event_examples.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3254b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = len(frames_all)\n",
    "N, H, W, n_ch = frames_all[0].shape\n",
    "print(f\"Loaded data with {n_frames} frames, {H}×{W} pixels, {n_ch} channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b83564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import akida_models\n",
    "from akida_models.model_io import load_model\n",
    "model = load_model(\"models/tenn_spatiotemporal_eye_buffer_i8_w8_a8.fbz\")\n",
    "print(f\"Model input shape: {model.input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b5460",
   "metadata": {},
   "outputs": [],
   "source": [
    "with set_akida_version(AkidaVersion.v2):\n",
    "    devices = akida.devices()\n",
    "    if len(devices) > 0:\n",
    "        print(f'Available devices: {[dev.desc for dev in devices]}')\n",
    "        device = devices[0]\n",
    "        print(device.version)\n",
    "        try:\n",
    "            akida_model.map(device)\n",
    "            print(f\"Mapping to Akida device {device.desc}.\")\n",
    "            mappedDevice = device.version\n",
    "        except Exception as e:\n",
    "            print(\"Model not compatible with FPGA. Running on CPU.\")\n",
    "            mappedDevice = \"CPU\"\n",
    "    else:\n",
    "        print(\"No Akida devices found, running on CPU.\")\n",
    "        mappedDevice = \"CPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e207083",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_ch == 2:\n",
    "    # e.g. channel 0 = red, channel 1 = blue\n",
    "    colors = np.array([[255, 0, 0], [0, 0, 255]], dtype=np.uint8)\n",
    "else:\n",
    "    # fallback: pick from matplotlib’s tab10 palette\n",
    "    import matplotlib\n",
    "    cmap = matplotlib.cm.get_cmap('tab10', n_ch)\n",
    "    colors = (cmap(range(n_ch))[:, :3] * 255).astype(np.uint8)\n",
    "\n",
    "# 3) Create one figure & axis to reuse\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "frame_number = 0\n",
    "\n",
    "# Define the size of the cross\n",
    "cross_size = 3\n",
    "\n",
    "# 4) Loop over frames, updating in place\n",
    "for f in frames_all:\n",
    "    frame_number += 1\n",
    "    # 4a) start from a mid-gray background\n",
    "    frame_vis = np.full((H, W, 3), 128, dtype=np.uint8)\n",
    "\n",
    "    f_np = f.numpy() if isinstance(f, tf.Tensor) else f  # Ensure f is a numpy array\n",
    "    frame = f_np[0]\n",
    "\n",
    "    # predict using the model\n",
    "    pred = model.predict(f_np)\n",
    "\n",
    "    pred = process_detector_prediction(tf.expand_dims(pred, 0))\n",
    "\n",
    "    y_pred_x = pred[:, 1] * W\n",
    "    y_pred_y = pred[:, 0] * H\n",
    "\n",
    "\n",
    "    # Convert to NumPy scalars\n",
    "    cx = int(y_pred_x.numpy().flatten()[0])\n",
    "    cy = int(y_pred_y.numpy().flatten()[0])\n",
    "\n",
    "    # 4b) paint each channel’s “events” on top\n",
    "    for ch in range(n_ch):\n",
    "        \n",
    "        mask = frame[ :, :, ch] > 0   # assuming >0 marks an event\n",
    "\n",
    "        pred_mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=bool)\n",
    "        # Draw a cross centered at (x, y)\n",
    "        for i in range(-cross_size, cross_size + 1):\n",
    "            if 0 <= cx + i < frame.shape[0]:\n",
    "                pred_mask[cx + i, cy] = True\n",
    "            if 0 <= cy + i < frame.shape[1]:\n",
    "                pred_mask[cx, cy + i] = True\n",
    "\n",
    "        frame_vis[mask] = colors[ch]\n",
    "        frame_vis[pred_mask] = [255, 255, 0]\n",
    "    \n",
    "    # 4c) update the image\n",
    "    ax.clear()\n",
    "    ax.imshow(frame_vis)\n",
    "    ax.set_title(f'Frame {frame_number}/{n_frames}')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # 4d) redraw the same window\n",
    "    clear_output(wait=True)\n",
    "    display(fig)\n",
    "    time.sleep(0.01)   # adjust playback speed\n",
    "\n",
    "# 5) close when done\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akida_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
