{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35785368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import cv2\n",
    "\n",
    "from cnn2snn import set_akida_version, AkidaVersion\n",
    "import akida\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31006aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gauge(value):\n",
    "    fig = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=value,\n",
    "        gauge={'axis': {'range': [0, 30]}},\n",
    "        domain={'x': [0, 1], 'y': [0, 1]},\n",
    "    ))\n",
    "    fig.update_layout(width=400, height=300)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax for an array of values\n",
    "def softmaxArray(values):\n",
    "    # Assuming array shape is (1, 1, 1, x), flatten to get the values\n",
    "    values = values.ravel()\n",
    "    exp_values = np.exp(values)\n",
    "    sum_exp = np.sum(exp_values)\n",
    "    softmax_values = exp_values / sum_exp\n",
    "    return softmax_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48246e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 96\n",
    "image_y = 96\n",
    "image_z = 3\n",
    "labels = [\"no person\", \"person\"]\n",
    "def decodeOutput(inp):\n",
    "        global akida_model\n",
    "        inp = cv2.resize(inp, (image_x, image_y))\n",
    "        inp = inp.reshape((-1, image_x, image_y, image_z))\n",
    "        timer_start = time.time()\n",
    "        predictions = softmaxArray(akida_model.predict(inp))\n",
    "        frame_time = time.time() - timer_start\n",
    "        fps = 1 / frame_time if frame_time > 0 else 0\n",
    "        confidences = {labels[i]: predictions[i] for i in range(len(predictions))}\n",
    "\n",
    "        return confidences, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd78e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(inp):\n",
    "\n",
    "  confidences, fps = decodeOutput(inp)\n",
    "\n",
    "  return confidences, create_gauge(round(fps, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantizeml import load_model\n",
    "from akida_models import fetch_file\n",
    "\n",
    "# Load the pre-trained quantized model\n",
    "model_file = fetch_file(\n",
    "    fname=\"akidanet_vww_i8_w4_a4.h5\",\n",
    "    origin=\"https://data.brainchip.com/models/AkidaV2/akidanet/akidanet_vww_i8_w4_a4.h5\",\n",
    "    cache_subdir='models')\n",
    "model_keras_quantized = load_model(model_file)\n",
    "model_keras_quantized.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618bfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn2snn import convert\n",
    "\n",
    "# Convert the model\n",
    "akida_model = convert(model_keras_quantized)\n",
    "akida_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with set_akida_version(AkidaVersion.v2):\n",
    "            devices = akida.devices()\n",
    "            if len(devices) > 0:\n",
    "                print(f'Available devices: {[dev.desc for dev in devices]}')\n",
    "                device = devices[0]\n",
    "                print(device.version)\n",
    "                try:\n",
    "                    akida_model.map(device)\n",
    "                    print(f\"Mapping to Akida device {device.desc}.\")\n",
    "                    mappedDevice = device.version\n",
    "                except Exception as e:\n",
    "                    print(\"Model not compatible with FPGA. Running on CPU.\")\n",
    "                    mappedDevice = \"CPU\"\n",
    "            else:\n",
    "                print(\"No Akida devices found, running on CPU.\")\n",
    "                mappedDevice = \"CPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "theme = gr.themes.Base(\n",
    "    text_size=\"sm\",\n",
    "    spacing_size=\"sm\",\n",
    "    radius_size=\"sm\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(\n",
    "    title=\"Brainchip\",\n",
    "    fill_width=True,\n",
    "    fill_height=True,\n",
    "    delete_cache=[180, 600],\n",
    "    theme=theme\n",
    ") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "        <h1 style=\"text-align: center;\">Akida Cloud</h1>\n",
    "        <br>\n",
    "        \"\"\")\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"## Image Classification\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_img = gr.Image(sources=[\"webcam\"], type=\"numpy\")\n",
    "        with gr.Column():\n",
    "            gr.Markdown(f\"\"\"Device: {mappedDevice}\"\"\")\n",
    "            output_label = gr.Label(num_top_classes=3)\n",
    "            plot = gr.Plot(label=\"Frames per second\")\n",
    "        dep = input_img.stream(classify_image, [input_img], [output_label, plot],\n",
    "                                time_limit=30, stream_every=0.1, concurrency_limit=30)        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akida_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
